{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run K_means for several k and print contingency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "import os, glob, inspect, sys\n",
    "\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "import epri_mc_lib as mc\n",
    "from importlib import reload\n",
    "reload(mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../../Data/Merged_data\"\n",
    "df = pd.read_csv(os.path.join(data_path, 'ALL_TUBE_PIPE_simulated.csv'), \n",
    "                 index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AUC_avg'] = mc.findAUC(df, A=df['A'], B=df['B'], p=df['p'], name='AUC_avg')\n",
    "df.drop(columns=[\"A\",\"B\",\"p\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CF_perm'] = df['mean_CF']/df['mean_perm'].astype('float64')\n",
    "df.drop(columns=[\"mean_MBN\",\"mean_perm\",\"mean_CF\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = mc.scale_general(df, MinMaxScaler())[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting sub samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tube, pipe, tube_wo_blind, tube_blind = mc.get_subsample_df(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_range = 2\n",
    "max_range = 8\n",
    "\n",
    "def plot_elbow_kmeans(feat_norm, title):\n",
    "    '''\n",
    "    Elbow plot\n",
    "    Args:\n",
    "    - feat_norm : pandas dataframe\n",
    "    - title : title of the figure ideally correpond to the samples\n",
    "    return plot\n",
    "    '''\n",
    "    \n",
    "    inertia = []\n",
    "    k_list = range(min_range, max_range+1)\n",
    "\n",
    "    for k in k_list:\n",
    "        km = KMeans(n_clusters = k, random_state= 0)\n",
    "        km.fit(feat_norm) \n",
    "        score = km.inertia_\n",
    "        inertia.append(score)\n",
    "\n",
    "\n",
    "    plt.figure(1 , figsize = (10 ,6))\n",
    "    plt.plot(np.arange(min_range , max_range+1) , inertia , 'o')\n",
    "    plt.plot(np.arange(min_range , max_range+1) , inertia , '-' , alpha = 0.5)\n",
    "\n",
    "    plt.xlabel('Number of Clusters', fontsize=20) , plt.ylabel('Inertia', fontsize=20)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tubes\n",
    "plot_elbow_kmeans(tube, title='Tubes simulated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tubes\n",
    "plot_elbow_kmeans(tube_wo_blind, title='Tubes labelled simulated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tubes\n",
    "plot_elbow_kmeans(tube_blind, title='Tubes Blind simulated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wcss(data):\n",
    "    '''\n",
    "    Calculate within class sum-squared value which represents loss in KMeans clustering\n",
    "    '''\n",
    "    wcss = []\n",
    "    for n in range(min_range, max_range):\n",
    "        kmeans = KMeans(n_clusters=n,random_state=42)\n",
    "        kmeans.fit(data)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    return wcss\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "def optimal_number_of_clusters(wcss):\n",
    "    '''\n",
    "    Calculate normal distance \n",
    "    '''\n",
    "    x1, y1 = min_range, wcss[0]\n",
    "    x2, y2 = max_range, wcss[len(wcss)-1]\n",
    "\n",
    "    distances = []\n",
    "    for i in range(len(wcss)):\n",
    "        x0 = i+2\n",
    "        y0 = wcss[i]\n",
    "        numerator = abs((y2-y1)*x0 - (x2-x1)*y0 + x2*y1 - y2*x1)\n",
    "        denominator = sqrt((y2 - y1)**2 + (x2 - x1)**2)\n",
    "        distances.append(numerator/denominator)\n",
    "    \n",
    "    return distances.index(max(distances)) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the within clusters sum-of-squares for n cluster amounts\n",
    "sum_of_squares = calculate_wcss(tube)\n",
    "    \n",
    "# calculating the optimal number of clusters\n",
    "n = optimal_number_of_clusters(sum_of_squares)\n",
    "print('Number of cluster =', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the within clusters sum-of-squares for n cluster amounts\n",
    "sum_of_squares = calculate_wcss(tube_wo_blind)\n",
    "    \n",
    "# calculating the optimal number of clusters\n",
    "n = optimal_number_of_clusters(sum_of_squares)\n",
    "print('Number of cluster =', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the within clusters sum-of-squares for n cluster amounts\n",
    "sum_of_squares = calculate_wcss(tube_blind)\n",
    "    \n",
    "# calculating the optimal number of clusters\n",
    "n = optimal_number_of_clusters(sum_of_squares)\n",
    "print('Number of cluster =', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test wo_blind sample:\n",
    "model = KMeans(n_clusters=2, random_state= 42)\n",
    "model.fit(tube_wo_blind.iloc[:, :]) \n",
    "labels_2 = model.predict(tube_wo_blind)\n",
    "silhouette = metrics.silhouette_score(tube_wo_blind, labels_2, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_wo_blind, labels_2)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_wo_blind, labels_2)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_wo_blind.index, labels_2)\n",
    "print(c_mat)\n",
    "#blind_labels = model.predict(tube_blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_2['sample'] = tube_wo_blind.index\n",
    "labeled_df_2['labels'] = labels_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contingency matrix and the value counts we can infer that there are 2 clusters grouped as\n",
    " - cluster 0 = T_T, T_OT, T_N_T, T_HAZ_T, T_FF, T_AR\n",
    " - cluster 1 = T_N, T_HAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test wo_blind sample:\n",
    "model = KMeans(n_clusters=3, random_state= 42)\n",
    "model.fit(tube_wo_blind.iloc[:, :]) \n",
    "labels_3 = model.predict(tube_wo_blind)\n",
    "silhouette = metrics.silhouette_score(tube_wo_blind, labels_3, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_wo_blind, labels_3)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_wo_blind, labels_3)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_wo_blind.index, labels_3)\n",
    "print(c_mat)\n",
    "#blind_labels = model.predict(tube_blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_3 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_3['sample'] = tube_wo_blind.index\n",
    "labeled_df_3['labels'] = labels_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_3.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contingency matrix and the value counts we can infer that there are 3 clusters grouped as\n",
    "\n",
    "-   cluster 0 = T_N_T, T_FF\n",
    "-   cluster 1 = T_N, T_HAZ\n",
    "-   cluster 2 = T_T, T_OT, T_AR, T_HAZ_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test wo_blind sample:\n",
    "model = KMeans(n_clusters=4, random_state= 42)\n",
    "model.fit(tube_wo_blind.iloc[:, :]) \n",
    "labels_4 = model.predict(tube_wo_blind)\n",
    "silhouette = metrics.silhouette_score(tube_wo_blind, labels_4, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_wo_blind, labels_4)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_wo_blind, labels_4)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_wo_blind.index, labels_4)\n",
    "print(c_mat)\n",
    "#blind_labels = model.predict(tube_blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_4 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_4['sample'] = tube_wo_blind.index\n",
    "labeled_df_4['labels'] = labels_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_4.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contingency matrix and the value counts we can infer that there are 4 clusters grouped as\n",
    "\n",
    "-    cluster 0 = T_FF, T_N_T\n",
    "-    cluster 1 = T_N, T_HAZ\n",
    "-    cluster 2 = T_OT\n",
    "-    cluster 3 = T_T, T_AR, T_HAZ_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test wo_blind sample:\n",
    "model = KMeans(n_clusters=5, random_state= 42)\n",
    "model.fit(tube_wo_blind.iloc[:, :]) \n",
    "labels_5 = model.predict(tube_wo_blind)\n",
    "silhouette = metrics.silhouette_score(tube_wo_blind, labels_5, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_wo_blind, labels_5)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_wo_blind, labels_5)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_wo_blind.index, labels_5)\n",
    "print(c_mat)\n",
    "#blind_labels = model.predict(tube_blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_5['sample'] = tube_wo_blind.index\n",
    "labeled_df_5['labels'] = labels_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_5.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contingency matrix and the value counts we can infer that there are 5 clusters grouped as\n",
    "\n",
    "-    cluster 0 = T_FF, T_N_T\n",
    "-    cluster 1 = T_HAZ \n",
    "-    cluster 2 = T_AR, T_HAZ_T, T_T\n",
    "-    cluster 3 = T_N\n",
    "-    cluster 4 = T_OT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test wo_blind sample:\n",
    "model = KMeans(n_clusters=6, random_state= 42)\n",
    "model.fit(tube_wo_blind.iloc[:, :]) \n",
    "labels_6 = model.predict(tube_wo_blind)\n",
    "silhouette = metrics.silhouette_score(tube_wo_blind, labels_6, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_wo_blind, labels_6)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_wo_blind, labels_6)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_wo_blind.index, labels_6)\n",
    "print(c_mat)\n",
    "#blind_labels = model.predict(tube_blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_6 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_6['sample'] = tube_wo_blind.index\n",
    "labeled_df_6['labels'] = labels_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_6.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contingency matrix and the value counts we can infer that there are 6 clusters grouped as\n",
    "\n",
    "-    cluster 0 = T_FF\n",
    "-    cluster 1 = T_AR, T_HAZ_T, T_T\n",
    "-    cluster 2 = T_HAZ\n",
    "-    cluster 3 = T_N_T\n",
    "-    cluster 4 = T_N\n",
    "-    cluster 5 = T_OT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test wo_blind sample:\n",
    "model = KMeans(n_clusters=7, random_state= 42)\n",
    "model.fit(tube_wo_blind.iloc[:, :]) \n",
    "labels_7 = model.predict(tube_wo_blind)\n",
    "silhouette = metrics.silhouette_score(tube_wo_blind, labels_7, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_wo_blind, labels_7)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_wo_blind, labels_7)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_wo_blind.index, labels_7)\n",
    "print(c_mat)\n",
    "#blind_labels = model.predict(tube_blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_7 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_7['sample'] = tube_wo_blind.index\n",
    "labeled_df_7['labels'] = labels_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_7.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contingency matrix and the value counts we can infer that there are 7 clusters grouped as\n",
    "\n",
    "-    cluster 0 = T_N_T \n",
    "-    cluster 1 = T_N\n",
    "-    cluster 2 = T_AR, T_HAZ_T, T_T\n",
    "-    cluster 3 = T_AR, T_HAZ_T, T_T\n",
    "-    cluster 4 = T_HAZ\n",
    "-    cluster 5 = T_FF\n",
    "-    cluster 6 = T_OT\n",
    "\n",
    "If we compare the clusters of 6 and 7 the clustering is the same with no further improvement. Hence, it would be appropriate to stop at cluster number 6 for labelled tube samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test wo_blind sample:\n",
    "model = KMeans(n_clusters=8, random_state= 42)\n",
    "model.fit(tube_wo_blind.iloc[:, :]) \n",
    "labels_8 = model.predict(tube_wo_blind)\n",
    "silhouette = metrics.silhouette_score(tube_wo_blind, labels_8, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_wo_blind, labels_8)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_wo_blind, labels_8)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_wo_blind.index, labels_8)\n",
    "print(c_mat)\n",
    "#blind_labels = model.predict(tube_blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_8 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_8['sample'] = tube_wo_blind.index\n",
    "labeled_df_8['labels'] = labels_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_8.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test blind sample:\n",
    "model = KMeans(n_clusters=2, random_state= 42)\n",
    "model.fit(tube_blind.iloc[:, :]) \n",
    "labels_b_2 = model.predict(tube_blind)\n",
    "silhouette = metrics.silhouette_score(tube_blind, labels_b_2, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_blind, labels_b_2)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_blind, labels_b_2)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_blind.index, labels_b_2)\n",
    "print(c_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_2['sample'] = tube_blind.index\n",
    "labeled_df_b_2['labels'] = labels_b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contingency matrix and the value counts we can infer that there are 2 clusters grouped as\n",
    "\n",
    "-    cluster 0 = T_B1, T_B2, T_B3, T_B5, T_B7, T_B8\n",
    "-    cluster 1 = T_B4, T_B6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test blind sample:\n",
    "model = KMeans(n_clusters=3, random_state= 42)\n",
    "model.fit(tube_blind.iloc[:, :]) \n",
    "labels_b_3 = model.predict(tube_blind)\n",
    "silhouette = metrics.silhouette_score(tube_blind, labels_b_3, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_blind, labels_b_3)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_blind, labels_b_3)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_blind.index, labels_b_3)\n",
    "print(c_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_3 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_3['sample'] = tube_blind.index\n",
    "labeled_df_b_3['labels'] = labels_b_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_3.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contingency matrix and the value counts we can infer that there are 3 clusters grouped as\n",
    "\n",
    "-    cluster 0 = T_B1, T_B3, T_B5, T_B8\n",
    "-    cluster 1 = T_B4, T_B6\n",
    "-    cluster 2 = T_B2, T_B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test blind sample:\n",
    "model = KMeans(n_clusters=4, random_state= 42)\n",
    "model.fit(tube_blind.iloc[:, :]) \n",
    "labels_b_4 = model.predict(tube_blind)\n",
    "silhouette = metrics.silhouette_score(tube_blind, labels_b_4, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_blind, labels_b_4)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_blind, labels_b_4)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_blind.index, labels_b_4)\n",
    "print(c_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_4 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_4['sample'] = tube_blind.index\n",
    "labeled_df_b_4['labels'] = labels_b_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_4.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contingency matrix and the value counts we can infer that there are 4 clusters grouped as\n",
    "\n",
    "-    cluster 0 = T_B1, T_B3, T_B5\n",
    "-    cluster 1 = T_B4, T_B6\n",
    "-    cluster 2 = T_B2, T_B7\n",
    "-    cluster 3 = T_B8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test blind sample:\n",
    "model = KMeans(n_clusters=5, random_state= 42)\n",
    "model.fit(tube_blind.iloc[:, :]) \n",
    "labels_b_5 = model.predict(tube_blind)\n",
    "silhouette = metrics.silhouette_score(tube_blind, labels_b_5, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_blind, labels_b_5)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_blind, labels_b_5)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_blind.index, labels_b_5)\n",
    "print(c_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_5['sample'] = tube_blind.index\n",
    "labeled_df_b_5['labels'] = labels_b_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_5.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contingency matrix and the value counts we can infer that there are 5 clusters grouped as\n",
    "\n",
    "-    cluster 0 = T_B1, T_B3, T_B5\n",
    "-    cluster 1 = T_B4, T_B6\n",
    "-    cluster 2 = T_B7\n",
    "-    cluster 3 = T_B8\n",
    "-    cluster 4 = T_B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test blind sample:\n",
    "model = KMeans(n_clusters=6, random_state= 42)\n",
    "model.fit(tube_blind.iloc[:, :]) \n",
    "labels_b_6 = model.predict(tube_blind)\n",
    "silhouette = metrics.silhouette_score(tube_blind, labels_b_6, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_blind, labels_b_6)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_blind, labels_b_6)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_blind.index, labels_b_6)\n",
    "print(c_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_6 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_6['sample'] = tube_blind.index\n",
    "labeled_df_b_6['labels'] = labels_b_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_6.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the contingency matrix and the value counts we can infer that there are 6 clusters grouped as\n",
    "\n",
    "-    cluster 0 = T_B4\n",
    "-    cluster 1 = T_B1, T_B3, T_B5\n",
    "-    cluster 2 = T_B7\n",
    "-    cluster 3 = T_B8\n",
    "-    cluster 4 = T_B2\n",
    "-    cluster 5 = T_B6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test blind sample:\n",
    "model = KMeans(n_clusters=7, random_state= 42)\n",
    "model.fit(tube_blind.iloc[:, :]) \n",
    "labels_b_7 = model.predict(tube_blind)\n",
    "silhouette = metrics.silhouette_score(tube_blind, labels_b_7, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_blind, labels_b_7)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_blind, labels_b_7)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_blind.index, labels_b_7)\n",
    "print(c_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_7 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_7['sample'] = tube_blind.index\n",
    "labeled_df_b_7['labels'] = labels_b_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_7.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test blind sample:\n",
    "model = KMeans(n_clusters=8, random_state= 42)\n",
    "model.fit(tube_blind.iloc[:, :]) \n",
    "labels_b_8 = model.predict(tube_blind)\n",
    "silhouette = metrics.silhouette_score(tube_blind, labels_b_8, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube_blind, labels_b_8)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube_blind, labels_b_8)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube_blind.index, labels_b_8)\n",
    "print(c_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_8 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_8['sample'] = tube_blind.index\n",
    "labeled_df_b_8['labels'] = labels_b_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_b_8.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion - I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above clustering patterns we can conclude that\n",
    "- {T_B1, T_B3, T_B5} = {T_AR, T_HAZ_T, T_T} not mapped one to one\n",
    "-  T_B8 = T_OT\n",
    "- {T_B4, T_B6}= {T_N, T_HAZ}  not mapped one to one\n",
    "- {T_B7, T_B2}= {T_FF, T_N_T} not mapped one to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "#test blind sample:\n",
    "model = KMeans(n_clusters=6, random_state= 42)\n",
    "model.fit(tube.iloc[:, :]) \n",
    "labels_tube = model.predict(tube)\n",
    "silhouette = metrics.silhouette_score(tube, labels_tube, metric='euclidean')\n",
    "print(silhouette)\n",
    "ch_score=metrics.calinski_harabasz_score(tube, labels_tube)\n",
    "print(ch_score)\n",
    "DB_score=metrics.davies_bouldin_score(tube, labels_tube)\n",
    "print(DB_score)\n",
    "c_mat=contingency_matrix(tube.index, labels_tube)\n",
    "print(c_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_tube = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_tube['sample'] = tube.index\n",
    "labeled_df_tube['labels'] = labels_tube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_tube.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion - II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above clustering pattern we can  further classify \n",
    "\n",
    "-    {T_B1, T_B3, T_B5} = {T_AR, T_HAZ_T, T_T} not mapped one to one\n",
    "-    T_B8 = T_OT\n",
    "-    T_B4 = T_N \n",
    "-    T_B6 = T_HAZ\n",
    "-    {T_B7, T_B2}= {T_FF, T_N_T} not mapped one to one\n",
    "-    T_B2 more likely to be T_FF and T_B7 to be T_N_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart(feature):\n",
    "    sample_1=labeled_df_tube[labeled_df_tube['sample']=='T_AR'][feature].value_counts()\n",
    "    sample_2=labeled_df_tube[labeled_df_tube['sample']=='T_FF'][feature].value_counts()\n",
    "    sample_3=labeled_df_tube[labeled_df_tube['sample']=='T_HAZ_T'][feature].value_counts()\n",
    "    sample_4=labeled_df_tube[labeled_df_tube['sample']=='T_N'][feature].value_counts()\n",
    "    sample_5=labeled_df_tube[labeled_df_tube['sample']=='T_T'][feature].value_counts()\n",
    "    sample_6=labeled_df_tube[labeled_df_tube['sample']=='T_HAZ'][feature].value_counts()\n",
    "    sample_7=labeled_df_tube[labeled_df_tube['sample']=='T_N_T'][feature].value_counts()\n",
    "    sample_8=labeled_df_tube[labeled_df_tube['sample']=='T_OT'][feature].value_counts()\n",
    "    df=pd.DataFrame([sample_1,sample_2,sample_3,sample_4,sample_5,sample_6,sample_7,sample_8])\n",
    "    df.index=['T_AR','T_FF','T_HAZ_T','T_N','T_T','T_HAZ','T_N_T','T_OT']\n",
    "    df.plot(kind='bar',stacked=True,figsize=(10,5))\n",
    "    plt.xlabel(\"Microstructures\",fontsize=18, fontweight='bold')\n",
    "    plt.ylabel(\"No. of simulated samples\",fontsize=14, fontweight='bold')\n",
    "    plt.title (\"Clustering of Tubes labelled simulated\",fontsize=16, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart_unknown(feature):\n",
    "    sample_1=labeled_df_tube[labeled_df_tube['sample']=='T_B1'][feature].value_counts()\n",
    "    sample_2=labeled_df_tube[labeled_df_tube['sample']=='T_B2'][feature].value_counts()\n",
    "    sample_3=labeled_df_tube[labeled_df_tube['sample']=='T_B3'][feature].value_counts()\n",
    "    sample_4=labeled_df_tube[labeled_df_tube['sample']=='T_B4'][feature].value_counts()\n",
    "    sample_5=labeled_df_tube[labeled_df_tube['sample']=='T_B5'][feature].value_counts()\n",
    "    sample_6=labeled_df_tube[labeled_df_tube['sample']=='T_B6'][feature].value_counts()\n",
    "    sample_7=labeled_df_tube[labeled_df_tube['sample']=='T_B7'][feature].value_counts()\n",
    "    sample_8=labeled_df_tube[labeled_df_tube['sample']=='T_B8'][feature].value_counts()\n",
    "    df=pd.DataFrame([sample_1,sample_2,sample_3,sample_4,sample_5,sample_6,sample_7,sample_8])\n",
    "    df.index=['T_B1','T_B2','T_B3','T_B4','T_B5','T_B6','T_B7','T_B8']\n",
    "    df.plot(kind='bar',stacked=True,figsize=(10,5))\n",
    "    plt.xlabel(\"Microstructures\",fontsize=18, fontweight='bold')\n",
    "    plt.ylabel(\"No. of simulated samples\",fontsize=14, fontweight='bold')\n",
    "    plt.title (\"Clustering of Tubes Blind simulated\",fontsize=16, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart_unknown('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
