{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model dendrogram on variation coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import os, glob, inspect, sys\n",
    "from sklearn import metrics\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "import epri_mc_lib as mc\n",
    "from importlib import reload\n",
    "reload(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../Data/Merged_data\"\n",
    "df = pd.read_csv(os.path.join(data_path, 'ALL_TUBE_PIPE_merge_1.csv'), \n",
    "                 index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting subsample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:16] # choosing tube specimen data only\n",
    "df.dropna(axis=1, inplace=True) # drop all nan columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_list=df[['TEP_mean_uV_C',\n",
    " 'TEP_error_uV_C',\n",
    " 'backscatter_avg',\n",
    " 'backscatter_std',\n",
    " 'Absorption_avg_50',\n",
    " 'Absorption_std_50',\n",
    " 'A',\n",
    " 'A std',\n",
    " 'B',\n",
    " 'B std',\n",
    " 'p',\n",
    " 'p std',\n",
    " 'Absorption_avg_100',\n",
    " 'Absorption_std_100',\n",
    " 'mean_CF',\n",
    " 'std_CF',\n",
    " 'mean_perm',\n",
    " 'std_perm']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_list.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_general(df, scaler):\n",
    "    ''' Scale a dataframe using a given scaler (fit and transform).\n",
    "        Keeps index and column names.\n",
    "        Return new dataframe, scaler.\n",
    "        \n",
    "        Args:\n",
    "        - df : pandas dataframe\n",
    "        - scaler : initialized sklearn scaler function\n",
    "        \n",
    "        return scaled df and fit scaler\n",
    "    '''\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "    return df_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(data):\n",
    "    '''\n",
    "    Plot correlation \n",
    "    Args:\n",
    "    - data: pd dataframe\n",
    "    '''\n",
    "    corr = data.corr()\n",
    "    sns.set(font_scale=1.2)\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    with sns.axes_style(\"white\"):\n",
    "        f, ax = plt.subplots(figsize=(12, 10))\n",
    "        ax = sns.heatmap(corr, mask=mask, square=True, cmap='RdBu_r', center=0, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating ther coefficient of variation CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_list['TEP_uV_C_CV']=CV_list['TEP_error_uV_C']/CV_list['TEP_mean_uV_C']\n",
    "CV_list['bkstr_CV']=CV_list['backscatter_std']/CV_list['backscatter_avg']\n",
    "CV_list['absp_50_CV']=CV_list['Absorption_std_50']/CV_list['Absorption_avg_50']\n",
    "CV_list['A_CV']=CV_list['A std']/CV_list['A']\n",
    "CV_list['B_CV']=CV_list['B std']/CV_list['B']\n",
    "CV_list['p_CV']=CV_list['p std']/CV_list['p']\n",
    "CV_list['absp_100_CV']=CV_list['Absorption_std_100']/CV_list['Absorption_avg_100']\n",
    "CV_list['CF_CV']=CV_list['std_CF']/CV_list['mean_CF']\n",
    "CV_list['perm_CV']=CV_list['std_perm']/CV_list['mean_perm']\n",
    "\n",
    "# we also drop the old feature columns\n",
    "CV_list.drop(['TEP_error_uV_C','TEP_mean_uV_C'\n",
    "              ,'backscatter_avg', 'backscatter_std','Absorption_avg_50','Absorption_std_50','A','A std','B',\n",
    "              'B std','p','p std', 'Absorption_avg_100', 'Absorption_std_100', 'mean_CF', 'std_CF', 'mean_perm',\n",
    "              'std_perm'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_list.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(CV_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We observe high correlation between some features, divide one by the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_list['CF_perm_CV'] = CV_list['CF_CV']/CV_list['perm_CV']\n",
    "CV_list['B_p_CV'] = CV_list['B_CV']/CV_list['p_CV']\n",
    "\n",
    "# we also drop the existing features\n",
    "CV_list.drop(['CF_CV', 'B_CV','p_CV','perm_CV'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_list.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(CV_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_list_scaled = mc.scale_general(CV_list, MinMaxScaler())[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering \n",
    "\n",
    "#### Algorithm Description\n",
    "1. Calculate distance between objects using pdist function\n",
    "2. Use linkage function to link pairs of objects that are in close proximity, build hierarchical cluster tree\n",
    "3. Determining the cut-off in the hierarchical tree \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=CV_list_scaled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Names of models using different metric and method for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1=pdist(X, 'euclidean')\n",
    "Z1=linkage(Y1, 'ward')\n",
    "\n",
    "Y2=pdist(X, 'euclidean')\n",
    "Z2=linkage(Y2, 'single')\n",
    "\n",
    "Y3=pdist(X, 'euclidean')\n",
    "Z3=linkage(Y3, 'average')\n",
    "\n",
    "Y4=pdist(X, 'cityblock')\n",
    "Z4=linkage(Y4, 'average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")            \n",
    "\n",
    "fig= plt.figure(figsize=(15, 6))\n",
    "dn = dendrogram(Z1, labels=X.index)\n",
    "sns.despine(left=True)\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Tubes')\n",
    "\n",
    "\n",
    "fig= plt.figure(figsize=(15, 6))\n",
    "dn = dendrogram(Z2,labels=X.index)\n",
    "sns.despine(left=True)\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Tubes')\n",
    "                \n",
    "\n",
    "fig= plt.figure(figsize=(15, 6))\n",
    "dn = dendrogram(Z3,labels=X.index)\n",
    "sns.despine(left=True)\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Tubes')\n",
    "                \n",
    "\n",
    "fig= plt.figure(figsize=(15, 6))\n",
    "dn = dendrogram(Z4,labels=X.index)\n",
    "sns.despine(left=True)                \n",
    "plt.ylabel('Distance')\n",
    "plt.title('Tubes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the cluster tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying dissimilarity using cophenetic correlation coefficient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, ccc_eu_ward = hierarchy.cophenet(Z1, Y1)\n",
    "c2, ccc_eu_single = hierarchy.cophenet(Z2, Y2)\n",
    "c3, ccc_eu_average = hierarchy.cophenet(Z3, Y3)\n",
    "c4, ccc_cb_average = hierarchy.cophenet(Z4, Y4)\n",
    "\n",
    "print(\"ccc_eu_ward :\", c1)\n",
    "print(\"ccc_eu_single :\", c2)\n",
    "print(\"ccc_eu_average :\", c3)\n",
    "print(\"ccc_cb_average :\", c4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The highest ccc is for using eu_avg, it is the most representable linkage dendrogram of our pdist data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Consistency\n",
    "we can determine the natural cluster division in a dataset is to compare the height of a link to its neighbouring links below it in the tree.\n",
    "This helps to indicate the distinction between division in the tree. A link with high consistency is said to have a its distance approximately the same as the distance of the objects it contains (the links below in the tree). On the other hand, a link with high inconsistency is said to have a distance whose link differs noticably from the links below it. Hence a high inconsistency indicates that the link joined above the leaf nodes is farther apart from the joined objects. \n",
    "\n",
    "The inconsistent coefficient is a quantified expression of the relative consistency of each link. The lead nodes (bottom object) has a zero inconsistency coefficient. \n",
    "\n",
    "\"This value compares\n",
    "the height of a link in a cluster hierarchy with the average height of links\n",
    "below it. Links that join distinct clusters have a high inconsistency coefficient;\n",
    "links that join indistinct clusters have a low inconsistency coefficient.\" (http://cda.psych.uiuc.edu/multivariate_fall_2013/matlab_help/cluster_analysis.pdf)\n",
    "\n",
    "Column Description of the inconsistency matrix\n",
    "\n",
    "1 Mean of the heights of all the links included in the calculation\n",
    "\n",
    "2 Standard deviation of all the links included in the calculation\n",
    "\n",
    "3 Number of links included in the calculation\n",
    "\n",
    "4 Inconsistency coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d is optional  depth of the comparison chooses how many levels below a link to compare\n",
    "#incons = hierarchy.inconsistent(Z, d)\n",
    "\n",
    "Z1_incons = hierarchy.inconsistent(Z1)\n",
    "Z2_incons = hierarchy.inconsistent(Z2)\n",
    "Z3_incons = hierarchy.inconsistent(Z3)\n",
    "Z4_incons = hierarchy.inconsistent(Z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Z1_inconsistency :\\n\", Z1_incons)\n",
    "\n",
    "print(\"\\nZ2_inconsistency :\\n\", Z2_incons)\n",
    "\n",
    "print(\"\\nZ3_inconsistency :\\n\", Z3_incons)\n",
    "\n",
    "print(\"\\nZ4_inconsistency :\\n\", Z4_incons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding natural divisions in data using the inconsistency coefficient to try find the cut-off the line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this returns a list with highest t (inconsistency coefficient), max number of cluster for the t and depth\n",
    "def inconsistency(linkage_matrix, CV_list_scaled, method):\n",
    "    for depth in np.arange(0,6):\n",
    "        incons = hierarchy.inconsistent(linkage_matrix, depth)\n",
    "        max_inc = hierarchy.maxinconsts(linkage_matrix, incons)\n",
    "        for t in np.unique(np.around(max_inc, 2)):\n",
    "            cluster = hierarchy.fclusterdata(CV_list_scaled, t=t, method=method)\n",
    "            print('depth:', depth, ': ', 't=', t, ' cluster = ', int(cluster.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z3_incons=inconsistency(Z3, CV_list_scaled, 'average')\n",
    "Z3_incons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z4_incons=inconsistency(Z4, CV_list_scaled, 'average')\n",
    "Z4_incons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our highest level of inconsistency coefficient is 1.15104191 as observed by Z3_inconsistency array above, hence why t=1.26 creates one cluster. And for t=0 we get 11 cluster, t=0.71 we get 8 clusters. That seems to be the optimal the model can generate in terms of distinction based on inconsistency coefficient.\n",
    "\n",
    "Below is a df grouping each specimen with its corresponding group in cluster value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z3_inconsistent_fcluster=fcluster(Z3, t=0.71, criterion='inconsistent')\n",
    "Z3_inconsistent_fcluster=pd.DataFrame(Z3_inconsistent_fcluster, index=X.index)\n",
    "Z3_inconsistent_fcluster.columns=['Cluster_incons']\n",
    "Z3_inconsistent_fcluster.sort_values(by=['Cluster_incons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow method\n",
    "Probably the most well known method, the elbow method, in which the sum of squares at each number of clusters is calculated and graphed, and the user looks for a change of slope from steep to shallow (an elbow) to determine the optimal number of clusters. This method is inexact, but still potentially helpful.\n",
    "\n",
    "Note, this method is inexact. And from the below results i does not seem to be clear if the elbow position is at 6 or 8. Use 6 based on observation judgement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_range = 2\n",
    "max_range = 15\n",
    "\n",
    "inertia = []\n",
    "k_list = range(min_range, max_range+1)\n",
    "\n",
    "for k in k_list:\n",
    "    km = KMeans(n_clusters = k, random_state= 0)\n",
    "    km.fit(X) \n",
    "    score = km.inertia_\n",
    "    inertia.append(score)\n",
    "\n",
    "\n",
    "plt.figure(1 , figsize = (10 ,6))\n",
    "plt.plot(np.arange(min_range , max_range+1) , inertia , 'o')\n",
    "plt.plot(np.arange(min_range , max_range+1) , inertia , '-' , alpha = 0.5)\n",
    "\n",
    "plt.xlabel('Number of Clusters') , plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Arbitrary Clusters\n",
    "#### Cut off line at 6 clusters based on elbow method using maxclust method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z3_maxclust_fcluster=fcluster(Z3, t=6, criterion='maxclust')\n",
    "Z3_maxclust_fcluster=pd.DataFrame(Z3_maxclust_fcluster, index=X.index)\n",
    "Z3_maxclust_fcluster.columns=['Cluster_maxclust']\n",
    "Z3_maxclust_fcluster.sort_values(by=['Cluster_maxclust'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cut-off line by observation for 'Euclidean Average' model of the dendrogram using distance as the criterion for fcluster function at 0.9 distance height as seen below - 0.9 is the observed distance value by judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")            \n",
    "                \n",
    "\n",
    "fig= plt.figure(figsize=(15, 6))\n",
    "dn = dendrogram(Z3,labels=X.index)\n",
    "sns.despine(left=True)\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Tubes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ax, fig = plt.subplots(figsize=(7,9))\n",
    "\n",
    "\n",
    "dendro = hierarchy.dendrogram(Z3, labels=X.index, leaf_rotation=0, orientation='left',\n",
    "                         color_threshold=0.9)\n",
    "\n",
    "for i, d, c in zip(dendro['icoord'], dendro['dcoord'], dendro['color_list']):\n",
    "    y = 0.5 * sum(i[1:3])\n",
    "    x = d[1]\n",
    "    plt.plot(x, y, 'o', c=c)\n",
    "    plt.annotate('%.3g'%x, (x, y), xytext=(5, -5),\n",
    "                 textcoords = 'offset points',\n",
    "                 va='bottom', ha='left',\n",
    "                 fontsize=10\n",
    "                )\n",
    "\n",
    "\n",
    "plt.xlabel('Distance')\n",
    "plt.title('All Tubes \\n Model 3')\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(CV_list_scaled, method='average', metric='euclidean', cmap='PuBu', figsize=(6,8), dendrogram_ratio=(0.2, 0.2), cbar_pos=(0.05, 0.85, 0.025, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the 'Cityblock Average' model it is more difficult to guess the cut-off line by judging the dendrogram tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ax, fig = plt.subplots(figsize=(7,9))\n",
    "\n",
    "\n",
    "dendro = hierarchy.dendrogram(Z4, labels=X.index, leaf_rotation=0, orientation='left',\n",
    "                         color_threshold=1.8)\n",
    "\n",
    "for i, d, c in zip(dendro['icoord'], dendro['dcoord'], dendro['color_list']):\n",
    "    y = 0.5 * sum(i[1:3])\n",
    "    x = d[1]\n",
    "    plt.plot(x, y, 'o', c=c)\n",
    "    plt.annotate('%.3g'%x, (x, y), xytext=(5, -5),\n",
    "                 textcoords = 'offset points',\n",
    "                 va='bottom', ha='left',\n",
    "                 fontsize=10\n",
    "                )\n",
    "\n",
    "\n",
    "plt.xlabel('Distance')\n",
    "plt.title('All Tubes \\n Model 4')\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(CV_list_scaled, method='average', metric='cityblock', cmap='PuBu', figsize=(6,8), dendrogram_ratio=(0.2, 0.2), cbar_pos=(0.05, 0.85, 0.025, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering group for 'Euclidean Average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z3_distance_fcluster=fcluster(Z3, t=0.9, criterion='distance')\n",
    "Z3_distance_fcluster=pd.DataFrame(Z3_distance_fcluster, index=X.index)\n",
    "Z3_distance_fcluster.columns=['Cluster_distance']\n",
    "Z3_distance_fcluster.sort_values(by=['Cluster_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Making one dataframe with all the clusters using different criterion\n",
    "df_clusters=pd.DataFrame([Z3_inconsistent_fcluster['Cluster_incons'],Z3_maxclust_fcluster['Cluster_maxclust'],Z3_distance_fcluster['Cluster_distance']])\n",
    "df_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters=df_clusters.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters.sort_values(by=['Cluster_distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
