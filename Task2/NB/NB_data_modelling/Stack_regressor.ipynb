{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9AtRF0x8jc8N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'epri_mc_lib_2' from '/home/marie-anne/code/Oct20_EPRI/Task2/NB/epri_mc_lib_2.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob, inspect, sys\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "import epri_mc_lib_2 as mc\n",
    "from importlib import reload\n",
    "reload(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yk56PIHyYkn0"
   },
   "outputs": [],
   "source": [
    "#Import dfs\n",
    "data = mc.load_data(os.path.join(os.path.dirname(os.getcwd()),'../Data/Merged_data/CopulaGAN_simulated_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KJIC</th>\n",
       "      <th>log_beta_avg</th>\n",
       "      <th>TEP_average</th>\n",
       "      <th>log_MS_Avg</th>\n",
       "      <th>PC_IF_2.25MHz</th>\n",
       "      <th>PC_IF_3.5MHz</th>\n",
       "      <th>PC_BS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_cw</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A286-80</th>\n",
       "      <td>0.170309</td>\n",
       "      <td>0.390684</td>\n",
       "      <td>0.387439</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.289459e-01</td>\n",
       "      <td>0.174966</td>\n",
       "      <td>0.060829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A286-80</th>\n",
       "      <td>0.076883</td>\n",
       "      <td>0.211567</td>\n",
       "      <td>0.299858</td>\n",
       "      <td>0.059858</td>\n",
       "      <td>5.438486e-01</td>\n",
       "      <td>0.624207</td>\n",
       "      <td>0.046113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A286-0</th>\n",
       "      <td>0.722217</td>\n",
       "      <td>0.418086</td>\n",
       "      <td>0.555533</td>\n",
       "      <td>0.068867</td>\n",
       "      <td>1.141398e-15</td>\n",
       "      <td>0.088545</td>\n",
       "      <td>0.692367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304-80</th>\n",
       "      <td>0.225209</td>\n",
       "      <td>0.632568</td>\n",
       "      <td>0.702281</td>\n",
       "      <td>0.955842</td>\n",
       "      <td>9.454126e-02</td>\n",
       "      <td>0.158487</td>\n",
       "      <td>0.615641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304-40</th>\n",
       "      <td>0.409809</td>\n",
       "      <td>0.239343</td>\n",
       "      <td>0.572501</td>\n",
       "      <td>0.726706</td>\n",
       "      <td>4.748123e-02</td>\n",
       "      <td>0.458641</td>\n",
       "      <td>0.330674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             KJIC  log_beta_avg  TEP_average  log_MS_Avg  PC_IF_2.25MHz  \\\n",
       "type_cw                                                                   \n",
       "A286-80  0.170309      0.390684     0.387439    0.020544   4.289459e-01   \n",
       "A286-80  0.076883      0.211567     0.299858    0.059858   5.438486e-01   \n",
       "A286-0   0.722217      0.418086     0.555533    0.068867   1.141398e-15   \n",
       "304-80   0.225209      0.632568     0.702281    0.955842   9.454126e-02   \n",
       "304-40   0.409809      0.239343     0.572501    0.726706   4.748123e-02   \n",
       "\n",
       "         PC_IF_3.5MHz     PC_BS  \n",
       "type_cw                          \n",
       "A286-80      0.174966  0.060829  \n",
       "A286-80      0.624207  0.046113  \n",
       "A286-0       0.088545  0.692367  \n",
       "304-80       0.158487  0.615641  \n",
       "304-40       0.458641  0.330674  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(800, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, 1:]\n",
    "y= data.iloc[:,0]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42\n",
    "                                                 )\n",
    "# get feature names\n",
    "feature_names=list(X_train)\n",
    "\n",
    "#check shape\n",
    "print(X.shape)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy regressor on all steel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: -0.175 (0.021)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate naive\n",
    "\n",
    "naive = DummyRegressor(strategy='median')\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(naive, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Baseline: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_dict\n",
    "\n",
    "model_GSCV = dict()\n",
    "\n",
    "model_GSCV['Elastic'] = ElasticNet()\n",
    "model_GSCV['Tree'] = DecisionTreeRegressor()\n",
    "model_GSCV['KNN'] = KNeighborsRegressor()\n",
    "model_GSCV['SVM'] = SVR()\n",
    "model_GSCV['RF'] = RandomForestRegressor()\n",
    "model_GSCV['XGB'] = xgb.XGBRegressor(objective= 'reg:squarederror',\n",
    "                        eval_metric = 'rmse',\n",
    "                        learning_rate = 0.01, \n",
    "                        nthread=4,\n",
    "                        seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define best_model:\n",
    "def best_model(data, steel, name, model):\n",
    "    '''run standard scaler and gridsearch CV pipeline on models\n",
    "    Args:\n",
    "        -model: initiated model \n",
    "        -name : name of model as str\n",
    "    return list of best estimator and table of results\n",
    "    '''\n",
    "    X = data[data.index.str.contains(steel)].iloc[:, 1:]\n",
    "    y= data[data.index.str.contains(steel)].iloc[:,0]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42\n",
    "                                                     )\n",
    "    # get feature names\n",
    "    feature_names=list(X_train)\n",
    "\n",
    "    #check shape\n",
    "    print(X.shape)\n",
    "    X_train.shape\n",
    "    \n",
    "    best_model_stack = list()\n",
    "    results_cv = dict()\n",
    "    def grid_csv(params):\n",
    "        \n",
    "        GSCV = GridSearchCV(model, param_grid = params, scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2', 'neg_root_mean_squared_error'], \n",
    "                            refit='neg_root_mean_squared_error', \n",
    "                            cv = 10, n_jobs=-1, verbose=True)\n",
    "        best_clf = GSCV.fit(X_train, y_train)\n",
    "        best_hyperparams = best_clf.best_params_\n",
    "        best_score = best_clf.best_score_\n",
    "        estimator = best_clf.best_estimator_\n",
    "        print(best_score, best_hyperparams, estimator)\n",
    "        table = best_clf.cv_results_\n",
    "        results_cv[name] = table\n",
    "        return estimator\n",
    "    \n",
    "    if name == 'Elastic':\n",
    "        params = {'l1_ratio' : [0, 0.25, 0.5, 1], \n",
    "                  'alpha' : [0, 0.5, 1, 2]} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'Tree':\n",
    "        params = {'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'criterion' : ['mse', 'friedman_mse', 'mae'],\n",
    "                  'max_depth' : np.arange(5, 15, 1)}\n",
    "        best_model_stack.append(grid_csv(params))\n",
    "        \n",
    "    if name == 'KNN':\n",
    "        params = {'n_neighbors' : np.arange(5, 25, 5),\n",
    "                 'weights' : ['uniform', 'distance'],\n",
    "                 'algorithm' : ['ball_tree', 'kd_tree', 'brute', 'auto']} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'SVM':\n",
    "        params = {'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                 'C' : [0.2, 0.5, 1]} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "\n",
    "\n",
    "    if name == 'RF': \n",
    "        params = {'n_estimators' : np.arange(100, 200, 50),\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'criterion' : ['mse', 'mae'],\n",
    "                  'max_depth' : np.arange(5, 15, 1),\n",
    "                 } \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'XGB':\n",
    "        params = {'n_estimators' : np.arange(500, 2000, 250),\n",
    "                  'gamma': np.arange(0.1, 1, 0.5),\n",
    "                  'reg_lambda':[1e-8,  1e-4],\n",
    "                  'max_depth' : np.arange(5, 15, 2),\n",
    "                 } \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "\n",
    "        \n",
    "    return best_model_stack, results_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n",
      "(267, 6)\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    0.4s finished\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py:765: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6364688397223085, tolerance: 0.0006363303857664925\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07973049184419759 {'alpha': 0, 'l1_ratio': 0} ElasticNet(alpha=0, l1_ratio=0)\n",
      "(267, 6)\n",
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08503580984748546 {'criterion': 'friedman_mse', 'max_depth': 5, 'max_features': 'log2'} DecisionTreeRegressor(criterion='friedman_mse', max_depth=5,\n",
      "                      max_features='log2')\n",
      "(267, 6)\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07223108863647813 {'algorithm': 'ball_tree', 'n_neighbors': 20, 'weights': 'uniform'} KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20)\n",
      "(267, 6)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07487829996468323 {'C': 0.5, 'kernel': 'rbf'} SVR(C=0.5)\n",
      "(267, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07392073521142135 {'criterion': 'mse', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 150} RandomForestRegressor(max_depth=5, max_features='log2', n_estimators=150)\n",
      "(267, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 25.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08066497809473835 {'gamma': 0.1, 'max_depth': 5, 'n_estimators': 500, 'reg_lambda': 1e-08} XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, eval_metric='rmse',\n",
      "             gamma=0.1, gpu_id=-1, importance_type='gain',\n",
      "             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=500, n_jobs=4, nthread=4,\n",
      "             num_parallel_tree=1, random_state=42, reg_alpha=0,\n",
      "             reg_lambda=1e-08, scale_pos_weight=1, seed=42, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "347\n",
      "(257, 6)\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    0.3s finished\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py:765: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7396850846650673, tolerance: 0.0014081543554993828\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0896263604895046 {'alpha': 0, 'l1_ratio': 0} ElasticNet(alpha=0, l1_ratio=0)\n",
      "(257, 6)\n",
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07010278424400937 {'criterion': 'mae', 'max_depth': 6, 'max_features': 'sqrt'} DecisionTreeRegressor(criterion='mae', max_depth=6, max_features='sqrt')\n",
      "(257, 6)\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06075575437241395 {'algorithm': 'ball_tree', 'n_neighbors': 20, 'weights': 'distance'} KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20, weights='distance')\n",
      "(257, 6)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06906438172923558 {'C': 0.5, 'kernel': 'rbf'} SVR(C=0.5)\n",
      "(257, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06010475003147238 {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 100} RandomForestRegressor(max_depth=7, max_features='sqrt')\n",
      "(257, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 22.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0670481414301956 {'gamma': 0.1, 'max_depth': 5, 'n_estimators': 500, 'reg_lambda': 0.0001} XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, eval_metric='rmse',\n",
      "             gamma=0.1, gpu_id=-1, importance_type='gain',\n",
      "             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=500, n_jobs=4, nthread=4,\n",
      "             num_parallel_tree=1, random_state=42, reg_alpha=0,\n",
      "             reg_lambda=0.0001, scale_pos_weight=1, seed=42, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "A286\n",
      "(227, 6)\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    0.2s finished\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py:765: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5507982982184569, tolerance: 0.0019156694644089222\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0815615293154635 {'alpha': 0, 'l1_ratio': 0} ElasticNet(alpha=0, l1_ratio=0)\n",
      "(227, 6)\n",
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0705281868013791 {'criterion': 'mae', 'max_depth': 7, 'max_features': 'sqrt'} DecisionTreeRegressor(criterion='mae', max_depth=7, max_features='sqrt')\n",
      "(227, 6)\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05689043604504949 {'algorithm': 'ball_tree', 'n_neighbors': 15, 'weights': 'uniform'} KNeighborsRegressor(algorithm='ball_tree', n_neighbors=15)\n",
      "(227, 6)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 105 out of 120 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06287603071772671 {'C': 0.2, 'kernel': 'rbf'} SVR(C=0.2)\n",
      "(227, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0614452793535093 {'criterion': 'mae', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 150} RandomForestRegressor(criterion='mae', max_depth=5, max_features='log2',\n",
      "                      n_estimators=150)\n",
      "(227, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 22.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06379062738109365 {'gamma': 0.1, 'max_depth': 5, 'n_estimators': 500, 'reg_lambda': 1e-08} XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, eval_metric='rmse',\n",
      "             gamma=0.1, gpu_id=-1, importance_type='gain',\n",
      "             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=500, n_jobs=4, nthread=4,\n",
      "             num_parallel_tree=1, random_state=42, reg_alpha=0,\n",
      "             reg_lambda=1e-08, scale_pos_weight=1, seed=42, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "316\n",
      "(249, 6)\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    0.3s finished\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py:765: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4620959838166905, tolerance: 0.00022699992350302037\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07087709661658369 {'alpha': 0, 'l1_ratio': 0} ElasticNet(alpha=0, l1_ratio=0)\n",
      "(249, 6)\n",
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05688191171916849 {'criterion': 'friedman_mse', 'max_depth': 5, 'max_features': 'log2'} DecisionTreeRegressor(criterion='friedman_mse', max_depth=5,\n",
      "                      max_features='log2')\n",
      "(249, 6)\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.050676280277032505 {'algorithm': 'ball_tree', 'n_neighbors': 20, 'weights': 'distance'} KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20, weights='distance')\n",
      "(249, 6)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05767511355157756 {'C': 1, 'kernel': 'rbf'} SVR(C=1)\n",
      "(249, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05066641748484337 {'criterion': 'mse', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 150} RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=150)\n",
      "(249, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 23.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06151612695826205 {'gamma': 0.1, 'max_depth': 5, 'n_estimators': 1250, 'reg_lambda': 0.0001} XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, eval_metric='rmse',\n",
      "             gamma=0.1, gpu_id=-1, importance_type='gain',\n",
      "             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=1250, n_jobs=4, nthread=4,\n",
      "             num_parallel_tree=1, random_state=42, reg_alpha=0,\n",
      "             reg_lambda=0.0001, scale_pos_weight=1, seed=42, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "all_results=dict()\n",
    "for steel in set(X.index.str.split('-').str[0]):\n",
    "    print(steel)\n",
    "    results_best_model = list()\n",
    "    scoring = dict()\n",
    "    for name, model in model_GSCV.items():\n",
    "\n",
    "        scores = best_model(data, steel, name, model)\n",
    "        results_best_model.append(scores[0][0])\n",
    "        scoring[name] = pd.DataFrame(scores[1][name])\n",
    "\n",
    "    #save params\n",
    "    with open(os.path.join(os.getcwd(), 'Results_CV/' + steel + '_result_CV.txt'), 'w') as file:\n",
    "        file.write(str(results_best_model))\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(os.getcwd(), 'Results_CV/' + steel + '_result_CV.xlsx')) as writer:\n",
    "        for df_name, df in scoring.items():\n",
    "            df.to_excel(writer, sheet_name=df_name) \n",
    "    all_results[steel] = results_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-162f5bcf80d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_results' is not defined"
     ]
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"[ElasticNet(alpha=0, l1_ratio=0), DecisionTreeRegressor(criterion='friedman_mse', max_depth=5,\\n\", \"                      max_features='sqrt'), KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20, weights='distance'), SVR(C=1), RandomForestRegressor(max_depth=6, max_features='log2')]\"]\n",
      "[\"[ElasticNet(alpha=0, l1_ratio=0), DecisionTreeRegressor(criterion='mae', max_depth=7, max_features='log2'), KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20, weights='distance'), SVR(C=0.5), RandomForestRegressor(max_depth=6, max_features='log2')]\"]\n",
      "[\"[ElasticNet(alpha=0, l1_ratio=0), DecisionTreeRegressor(criterion='mae', max_depth=5, max_features='sqrt'), KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20), SVR(C=0.5), RandomForestRegressor(criterion='mae', max_depth=5, max_features='sqrt',\\n\", '                      n_estimators=150)]']\n",
      "[\"[ElasticNet(alpha=0, l1_ratio=0), DecisionTreeRegressor(max_depth=6, max_features='sqrt'), KNeighborsRegressor(algorithm='ball_tree', n_neighbors=15), SVR(C=0.2), RandomForestRegressor(criterion='mae', max_depth=5, max_features='log2')]\"]\n"
     ]
    }
   ],
   "source": [
    "for steel in set(X.index.str.split('-').str[0]):\n",
    "\n",
    "    with open('Results_CV/' + steel + '_result_CV.txt', 'r') as file:\n",
    "        print(list(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ElasticNet(alpha=0, l1_ratio=0), DecisionTreeRegressor(criterion='mae', max_depth=7, max_features='sqrt'), KNeighborsRegressor(algorithm='ball_tree', n_neighbors=15), SVR(C=0.2), RandomForestRegressor(criterion='mae', max_depth=5, max_features='log2',\n",
      "                      n_estimators=150), XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, eval_metric='rmse',\n",
      "             gamma=0.1, gpu_id=-1, importance_type='gain',\n",
      "             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=500, n_jobs=4, nthread=4,\n",
      "             num_parallel_tree=1, random_state=42, reg_alpha=0,\n",
      "             reg_lambda=1e-08, scale_pos_weight=1, seed=42, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)]\n",
      "[ElasticNet(alpha=0, l1_ratio=0), DecisionTreeRegressor(criterion='friedman_mse', max_depth=5,\n",
      "                      max_features='log2'), KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20), SVR(C=0.5), RandomForestRegressor(max_depth=5, max_features='log2', n_estimators=150), XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, eval_metric='rmse',\n",
      "             gamma=0.1, gpu_id=-1, importance_type='gain',\n",
      "             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=500, n_jobs=4, nthread=4,\n",
      "             num_parallel_tree=1, random_state=42, reg_alpha=0,\n",
      "             reg_lambda=1e-08, scale_pos_weight=1, seed=42, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)]\n",
      "[ElasticNet(alpha=0, l1_ratio=0), DecisionTreeRegressor(criterion='friedman_mse', max_depth=5,\n",
      "                      max_features='log2'), KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20, weights='distance'), SVR(C=1), RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=150), XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, eval_metric='rmse',\n",
      "             gamma=0.1, gpu_id=-1, importance_type='gain',\n",
      "             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=1250, n_jobs=4, nthread=4,\n",
      "             num_parallel_tree=1, random_state=42, reg_alpha=0,\n",
      "             reg_lambda=0.0001, scale_pos_weight=1, seed=42, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)]\n",
      "[ElasticNet(alpha=0, l1_ratio=0), DecisionTreeRegressor(criterion='mae', max_depth=6, max_features='sqrt'), KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20, weights='distance'), SVR(C=0.5), RandomForestRegressor(max_depth=7, max_features='sqrt'), XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, eval_metric='rmse',\n",
      "             gamma=0.1, gpu_id=-1, importance_type='gain',\n",
      "             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=500, n_jobs=4, nthread=4,\n",
      "             num_parallel_tree=1, random_state=42, reg_alpha=0,\n",
      "             reg_lambda=0.0001, scale_pos_weight=1, seed=42, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)]\n"
     ]
    }
   ],
   "source": [
    "for steel in set(X.index.str.split('-').str[0]):\n",
    "\n",
    "    with open(os.path.join(os.getcwd(), 'Results_CV/' + steel + '_result_CV.txt'), 'r') as file:\n",
    "        print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_dict\n",
    "models = dict()\n",
    "\n",
    "models['Elastic'] = ElasticNet('alpha': 0, 'l1_ratio': 0)\n",
    "models['Tree'] = DecisionTreeRegressor()\n",
    "models['KNN'] = KNeighborsRegressor()\n",
    "models['SVM'] = SVR()\n",
    "models['RF'] = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, steel, name, model):\n",
    "    X = data[data.index.str.contains(steel)].iloc[:, 1:]\n",
    "    y= data[data.index.str.contains(steel)].iloc[:,0]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42\n",
    "                                                     )\n",
    "   \n",
    "    if name == 'XGB':\n",
    "        X_train_df= pd.DataFrame(X_train, columns=feature_names)\n",
    "        clf = model.fit(X_train_df, y_train)\n",
    "    else:\n",
    "        clf = model.fit(X_train, y_train)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:01:59] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { metrics } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit models\n",
    "regressors = dict()\n",
    "for steel in set(X.index.str.split('-').str[0]):\n",
    "    print(steel)\n",
    "    for name, model in models.items():\n",
    "        regressors[name] = train_model(data, steel, name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "(249, 6)\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    1.5s finished\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py:765: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4620959838166905, tolerance: 0.00022699992350302037\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07087709661658369 {'alpha': 0, 'l1_ratio': 0} ElasticNet(alpha=0, l1_ratio=0)\n",
      "(249, 6)\n",
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05958007800562062 {'criterion': 'mse', 'max_depth': 5, 'max_features': 'log2'} DecisionTreeRegressor(max_depth=5, max_features='log2')\n",
      "(249, 6)\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 120 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.050676280277032505 {'algorithm': 'ball_tree', 'n_neighbors': 20, 'weights': 'distance'} KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20, weights='distance')\n",
      "(249, 6)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "-0.05767511355157756 {'C': 1, 'kernel': 'rbf'} SVR(C=1)\n",
      "(249, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05038353321190096 {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 100} RandomForestRegressor(max_depth=7, max_features='sqrt')\n",
      "347\n",
      "(257, 6)\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    0.2s finished\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py:765: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7396850846650673, tolerance: 0.0014081543554993828\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0896263604895046 {'alpha': 0, 'l1_ratio': 0} ElasticNet(alpha=0, l1_ratio=0)\n",
      "(257, 6)\n",
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07444422585939163 {'criterion': 'mae', 'max_depth': 5, 'max_features': 'sqrt'} DecisionTreeRegressor(criterion='mae', max_depth=5, max_features='sqrt')\n",
      "(257, 6)\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06075575437241395 {'algorithm': 'ball_tree', 'n_neighbors': 20, 'weights': 'distance'} KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20, weights='distance')\n",
      "(257, 6)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 105 out of 120 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06906438172923558 {'C': 0.5, 'kernel': 'rbf'} SVR(C=0.5)\n",
      "(257, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05974730414559981 {'criterion': 'mse', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 150} RandomForestRegressor(max_depth=6, max_features='log2', n_estimators=150)\n",
      "304\n",
      "(267, 6)\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    0.2s finished\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py:765: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6364688397223085, tolerance: 0.0006363303857664925\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07973049184419759 {'alpha': 0, 'l1_ratio': 0} ElasticNet(alpha=0, l1_ratio=0)\n",
      "(267, 6)\n",
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08599146120941852 {'criterion': 'mae', 'max_depth': 5, 'max_features': 'auto'} DecisionTreeRegressor(criterion='mae', max_depth=5, max_features='auto')\n",
      "(267, 6)\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07223108863647813 {'algorithm': 'ball_tree', 'n_neighbors': 20, 'weights': 'uniform'} KNeighborsRegressor(algorithm='ball_tree', n_neighbors=20)\n",
      "(267, 6)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07487829996468323 {'C': 0.5, 'kernel': 'rbf'} SVR(C=0.5)\n",
      "(267, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07400169581263163 {'criterion': 'mse', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 150} RandomForestRegressor(max_depth=5, max_features='log2', n_estimators=150)\n",
      "A286\n",
      "(227, 6)\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    0.2s finished\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py:765: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5507982982184569, tolerance: 0.0019156694644089222\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0815615293154635 {'alpha': 0, 'l1_ratio': 0} ElasticNet(alpha=0, l1_ratio=0)\n",
      "(227, 6)\n",
      "Fitting 10 folds for each of 90 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06886182371766462 {'criterion': 'mae', 'max_depth': 5, 'max_features': 'log2'} DecisionTreeRegressor(criterion='mae', max_depth=5, max_features='log2')\n",
      "(227, 6)\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05689043604504949 {'algorithm': 'ball_tree', 'n_neighbors': 15, 'weights': 'uniform'} KNeighborsRegressor(algorithm='ball_tree', n_neighbors=15)\n",
      "(227, 6)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 105 out of 120 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06287603071772671 {'C': 0.2, 'kernel': 'rbf'} SVR(C=0.2)\n",
      "(227, 6)\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06050935743966529 {'criterion': 'mae', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100} RandomForestRegressor(criterion='mae', max_depth=5, max_features='sqrt')\n"
     ]
    }
   ],
   "source": [
    "for steel in set(X.index.str.split('-').str[0]):\n",
    "    print(steel)\n",
    "    results_best_model = list()\n",
    "    scoring = dict()\n",
    "    for name, model in model_GSCV.items():\n",
    "\n",
    "        scores = best_model(data, steel, name, model)\n",
    "        results_best_model.append(scores[0])\n",
    "        scoring[name] = pd.DataFrame(scores[1][name])\n",
    "\n",
    "    #save params\n",
    "    with open(os.path.join(os.path.dirname(os.getcwd()), '/Results/' + steel + '_result_CV.csv'), 'w') as file:\n",
    "        file.write(str(results_best_model))\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(os.path.dirname(os.getcwd()), '/Results/' + steel + '_result_CV.xlsx')) as writer:\n",
    "        for df_name, df in scoring.items():\n",
    "            df.to_excel(writer, sheet_name=df_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS4A-Team18-Vaccine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
