{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run gridsearch, plot regression and features importance\n",
    "\n",
    "on original and simulated data\n",
    "\n",
    "save results to csv or excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AtRF0x8jc8N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob, inspect, sys, pickle, warnings\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "import epri_mc_lib_2 as mc\n",
    "from importlib import reload\n",
    "reload(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define best_model:\n",
    "def best_model(X_train, y_train, steel, name, model):\n",
    "    '''run standard scaler and gridsearch CV pipeline on models\n",
    "    Args:\n",
    "        -model: initiated model \n",
    "        -name : name of model as str\n",
    "    return list of best estimator and table of results\n",
    "    '''\n",
    "    X_train = X_train[X_train.index.str.contains(steel)]\n",
    "    y_train= y_train[y_train.index.str.contains(steel)]\n",
    "\n",
    "    \n",
    "    best_model_stack = list()\n",
    "    results_cv = dict()\n",
    "    \n",
    "    def grid_csv(params):\n",
    "        \n",
    "        GSCV = GridSearchCV(model, param_grid = params, scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2', 'neg_root_mean_squared_error'], \n",
    "                            refit='neg_root_mean_squared_error', \n",
    "                            cv = 5, n_jobs=-1, verbose=True)\n",
    "        best_clf = GSCV.fit(X_train, y_train)\n",
    "        best_hyperparams = best_clf.best_params_\n",
    "        best_score = best_clf.best_score_\n",
    "        estimator = best_clf.best_estimator_\n",
    "        print(best_score, best_hyperparams, estimator)\n",
    "        table = best_clf.cv_results_\n",
    "        results_cv[name] = table\n",
    "        return estimator\n",
    " \n",
    "        \n",
    "    if name == 'Ridge':\n",
    "        params = {'solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'], \n",
    "                  'alpha' :  np.arange(0.01, 1, 0.05)} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'Elastic':\n",
    "        params = {'l1_ratio' : [0, 0.25, 0.5, 1], \n",
    "                  'alpha' : np.arange(0.01, 1, 0.05)} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'Tree':\n",
    "        params = {'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'criterion' : ['mse', 'friedman_mse', 'mae'],\n",
    "                  'max_depth' : np.arange(3, 15, 1)}\n",
    "        best_model_stack.append(grid_csv(params))\n",
    "        \n",
    "    if name == 'KNN':\n",
    "        params = {'n_neighbors' : np.arange(5, 50, 5),\n",
    "                 'weights' : ['uniform', 'distance'],\n",
    "                 'algorithm' : ['ball_tree', 'kd_tree', 'brute', 'auto']} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'SVM':\n",
    "        params = {'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                 'C' : [0.2, 0.5, 1]} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "\n",
    "\n",
    "    if name == 'RF': \n",
    "        params = {'n_estimators' : np.arange(100, 1000, 200),\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'criterion' : ['mse', 'mae'],\n",
    "                  'max_depth' : np.arange(3, 15, 1),\n",
    "                 } \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'XGB':\n",
    "        params = {'n_estimators' : np.arange(100, 1000, 200),\n",
    "                  'gamma': np.arange(0.05, 0.8, 0.5),\n",
    "                  'reg_lambda':[1e-8,  1e-4],\n",
    "                  'max_depth' : np.arange(3, 10, 2),\n",
    "                 } \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "\n",
    "        \n",
    "    return best_model_stack, results_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define best_model:\n",
    "def best_model_bayes(X_train, y_train, steel, name, model):\n",
    "    warnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')\n",
    "    \n",
    "    '''run standard scaler and gridsearch CV pipeline on models\n",
    "    Args:\n",
    "        -model: initiated model \n",
    "        -name : name of model as str\n",
    "    return list of best estimator and table of results\n",
    "    '''\n",
    "    X_train = X_train[X_train.index.str.contains(steel)]\n",
    "    y_train= y_train[y_train.index.str.contains(steel)]\n",
    "\n",
    "    \n",
    "    best_model_stack = list()\n",
    "    results_cv = dict()\n",
    "    \n",
    "    def grid_csv(params):\n",
    "        \n",
    "        GSCV = BayesSearchCV(model, search_spaces = params, scoring = 'neg_root_mean_squared_error', \n",
    "                            cv = 10, n_jobs=-1, verbose=0)\n",
    "        best_clf = GSCV.fit(X_train, y_train)\n",
    "        best_hyperparams = best_clf.best_params_\n",
    "        best_score = best_clf.best_score_\n",
    "        estimator = best_clf.best_estimator_\n",
    "        print(best_score, best_hyperparams, estimator)\n",
    "        table = best_clf.cv_results_\n",
    "        results_cv[name] = table\n",
    "        return estimator\n",
    "        \n",
    "    if name == 'Ridge':\n",
    "        params = {'solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'], \n",
    "                  'alpha' :  np.arange(0.01, 1, 0.05)} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'Elastic':\n",
    "        params = {'l1_ratio' : [0, 0.25, 0.5, 1], \n",
    "                  'alpha' : np.arange(0.01, 1, 0.02)} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'Tree':\n",
    "        params = {'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'criterion' : ['mse', 'friedman_mse', 'mae'],\n",
    "                  'max_depth' : np.arange(3, 15, 1)}\n",
    "        best_model_stack.append(grid_csv(params))\n",
    "        \n",
    "    if name == 'KNN':\n",
    "        params = {'n_neighbors' : np.arange(5, 100, 5),\n",
    "                 'weights' : ['uniform', 'distance'],\n",
    "                 'algorithm' : ['ball_tree', 'kd_tree', 'brute', 'auto']} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'SVM':\n",
    "        params = {'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                 'C' : np.arange(0.01, 1, 0.02)} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "\n",
    "\n",
    "    if name == 'RF': \n",
    "        params = {'n_estimators' : np.arange(100, 1000, 50),\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'criterion' : ['mse', 'mae'],\n",
    "                  'max_depth' : np.arange(3, 15, 1),\n",
    "                  'min_weight_fraction_leaf': np.arange(0, 0.6, 0.2)\n",
    "                 } \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'XGB':\n",
    "        params = {'n_estimators' : np.arange(100, 1000, 200),\n",
    "                  'gamma': np.arange(0.05, 0.8, 0.2),\n",
    "                  'reg_alpha' : [1e-8, 1e-6, 1e-4, 1e-2],\n",
    "                  'reg_lambda':[1e-8, 1e-6, 1e-4, 1e-2],\n",
    "                  'max_depth' : np.arange(3, 15, 2),\n",
    "                  'gamma': np.arange(0.1, 1, 0.2),\n",
    "                  'subsample': np.arange(0.3, 1, 0.1),\n",
    "                  'colsample_bytree': np.arange(0.3, 1, 0.1), \n",
    "                  'min_child_weight': np.arange(1, 6, 2),\n",
    "                 } \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "\n",
    "        \n",
    "    return best_model_stack, results_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test, y_test, steel, name, model):\n",
    "    '''\n",
    "    predict real values using train models\n",
    "    Args:\n",
    "    - steel : id number\n",
    "    - X_train, X_test : pandas df of features\n",
    "    - y_train, y_test : pandas df of label, shape 1\n",
    "    - name : name of the model as str\n",
    "    - model: model with params\n",
    "    return y_pred\n",
    "    '''\n",
    "    \n",
    "    X_train = X_train[X_train.index.str.contains(steel)]\n",
    "    y_train = y_train[y_train.index.str.contains(steel)]\n",
    "    X_test = X_test[X_test.index.str.contains(steel)]\n",
    "    y_test = y_test[y_test.index.str.contains(steel)]\n",
    "\n",
    "    \n",
    "    if name == 'XGB':\n",
    "        X_train_df= pd.DataFrame(X_train, columns=feature_names)\n",
    "        reg = model.fit(X_train_df, y_train)\n",
    "\n",
    "    else:\n",
    "        reg = model.fit(X_train, y_train)\n",
    "        \n",
    "    y_pred = reg.predict(X_test)\n",
    "       \n",
    "    R2_train = r2_score(y_train, reg.predict(X_train))\n",
    "    R2_test =  r2_score(y_test, y_pred)\n",
    "    \n",
    "    RMSE_training = np.sqrt(mean_squared_error(y_train, reg.predict(X_train)))\n",
    "    RMSE_testing = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    score_sample = pd.DataFrame({'RMSE_train': RMSE_training, 'RMSE_test': RMSE_testing,\n",
    "                                    'R2_train':R2_train, 'R2_test':R2_test,\n",
    "                                     'model':name, 'type': steel\n",
    "                                    }, index=[0])\n",
    "    print(score_sample)\n",
    "    \n",
    "    sns.scatterplot(x=y_test, y=y_pred)\n",
    "    plt.plot([0, 250], [0, 250])\n",
    "    plt.xlim([0, 250])\n",
    "    plt.ylim([0, 250])\n",
    "    plt.xlabel(\"Fracture Toughness\")\n",
    "    plt.ylabel(\"Predicted Fracture Toughness\")\n",
    "    plt.title(steel + '\\n' + str(model))\n",
    "    plt.show()\n",
    "    \n",
    "    return reg, score_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_pred(steel, X_val_real, y_val_real, model):\n",
    "    '''\n",
    "    predict real values using train models\n",
    "    Args:\n",
    "    - steel : id number\n",
    "    - X_val_real : pandas df of features\n",
    "    - y_val_real : pandas df of label, shape 1\n",
    "    - model: trained model\n",
    "    return y_pred\n",
    "    '''\n",
    "    X_val_real = X_val_real[X_val_real.index.str.contains(steel)]\n",
    "    y_val_real = y_val_real[y_val_real.index.str.contains(steel)]\n",
    "\n",
    "    reg_real = model.predict(X_val_real)\n",
    "\n",
    "    print(\"r2 score for testing: \", r2_score(y_val_real, reg_real))\n",
    "    print(\"RMSE score for testing: \", np.sqrt(mean_squared_error(y_val_real, reg_real)))\n",
    "    \n",
    "    score_real = pd.DataFrame({'R2': r2_score(y_val_real, reg_real), 'RMSE': np.sqrt(mean_squared_error(y_val_real, reg_real)),\n",
    "                                     'model':name, 'type': steel\n",
    "                                    }, index=[0])\n",
    "\n",
    "    sns.set(style='white')\n",
    "    sns.scatterplot(x=y_val_real, y=reg_real)\n",
    "    plt.plot([0, 250], [0, 250])\n",
    "    plt.xlim([0, 250])\n",
    "    plt.ylim([0, 250])\n",
    "    plt.xlabel(\"Fracture Toughness\")\n",
    "    plt.ylabel(\"Predicted Fracture Toughness\")\n",
    "    plt.title(steel + ', ' + name)\n",
    "    plt.show()\n",
    "    \n",
    "    return reg_real, score_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_real(path, scaler):\n",
    "    '''\n",
    "    load_data for consistency columns in analyses.\n",
    "    Args:\n",
    "    - path : path to csv file\n",
    "    - scaler :sklearn scaler\n",
    "    return X, y\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df.index = df.index.str.rstrip('-12345')\n",
    "    df = df.groupby('ID').mean()\n",
    "    df['log_MS_Avg'] = np.log(df['MS_Avg'])\n",
    "    df['log_beta_avg'] = np.log(df['Beta_avg']) \n",
    "    df = df[mc.regression_cols].dropna(how='any')\n",
    "    y_val_real = df['KJIC']\n",
    "    X_val_real = df.drop(columns=['KJIC'])\n",
    "    X_val_real = pd.DataFrame(scaler.transform(X_val_real), columns=X_val_real.columns, index=X_val_real.index)\n",
    "    return  X_val_real, y_val_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic features importances:\n",
    "def get_feature_importance(name, model, feature_names):\n",
    "    '''return classical feature importances\n",
    "    Args:\n",
    "        -name:str\n",
    "        -model: trained model\n",
    "    return importance as a df    \n",
    "    '''\n",
    "    if name == 'Ridge' or name == 'Elastic':\n",
    "        importance = model.coef_\n",
    "        importance_df = pd.DataFrame(importance.T, columns=[name], index=feature_names)\n",
    "        importance_df.sort_values(name, ascending=True, inplace=True)\n",
    "       \n",
    "    if name == 'KNN' or name == 'SVM':\n",
    "        pass\n",
    "        \n",
    "    if name == 'RF' or name == 'Tree': \n",
    "        importance = model.feature_importances_\n",
    "        rel_importance = 100.0 * (importance / importance.sum())\n",
    "        importance_df = pd.DataFrame(rel_importance.T, columns=[name], index=feature_names)\n",
    "        importance_df.sort_values(name, ascending=True, inplace=True)\n",
    " \n",
    "    if name == 'XGB':\n",
    "        importance = model.feature_importances_\n",
    "        rel_importance = 100.0 * (importance / importance.sum())\n",
    "        importance_df = pd.DataFrame(rel_importance.T, columns=['XGB'], index=feature_names)\n",
    "        importance_df.sort_values('XGB', ascending=True, inplace=True)\n",
    "         \n",
    "    return importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import df and train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yk56PIHyYkn0"
   },
   "outputs": [],
   "source": [
    "X_train_ori, X_test_ori, y_train_ori, y_test_ori, scaler = mc.load_data(os.path.join(os.path.dirname(os.getcwd()),'../Data/Merged_data/CopulaGAN_simulated_data_up.csv'),\n",
    "                                               MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature names\n",
    "feature_names=list(X_train_ori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy regressor on all steel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate naive\n",
    "\n",
    "naive = DummyRegressor(strategy='median')\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(naive, X_train_ori, y_train_ori, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Baseline: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_dict\n",
    "\n",
    "model_GSCV = dict()\n",
    "\n",
    "model_GSCV['Ridge'] = Ridge()\n",
    "model_GSCV['Elastic'] = ElasticNet()\n",
    "model_GSCV['Tree'] = DecisionTreeRegressor()\n",
    "model_GSCV['KNN'] = KNeighborsRegressor()\n",
    "model_GSCV['SVM'] = SVR()\n",
    "model_GSCV['RF'] = RandomForestRegressor()\n",
    "model_GSCV['XGB'] = xgb.XGBRegressor(objective= 'reg:squarederror',\n",
    "                        eval_metric = 'rmse',\n",
    "                        learning_rate = 0.01, \n",
    "                        nthread=4,\n",
    "                        seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_bayes=dict()\n",
    "for steel in set(X_train_ori.index.str.split('-').str[0]):\n",
    "    print(steel)\n",
    "    results_best_model_bayes = list()\n",
    "    scoring_bayes = dict()\n",
    "    for name, model in model_GSCV.items():\n",
    "\n",
    "        scores = best_model_bayes(X_train_ori, y_train_ori, steel, name, model)\n",
    "        results_best_model_bayes.append(scores[0][0])\n",
    "        scoring_bayes[name] = pd.DataFrame(scores[1][name])\n",
    "        \n",
    "    all_results_bayes[steel] = results_best_model_bayes\n",
    "\n",
    "    #save params\n",
    "\n",
    "    with open('Results_CV/Bayes_all_results_CV.p', 'wb') as fp:\n",
    "        pickle.dump(all_results_bayes, fp, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classic gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results=dict()\n",
    "for steel in set(X_train_ori.index.str.split('-').str[0]):\n",
    "    print(steel)\n",
    "    results_best_model = list()\n",
    "    scoring = dict()\n",
    "    for name, model in model_GSCV.items():\n",
    "\n",
    "        scores = best_model(X_train_ori, y_train_ori, steel, name, model)\n",
    "        results_best_model.append(scores[0][0])\n",
    "        scoring[name] = pd.DataFrame(scores[1][name])\n",
    "\n",
    "    #save params\n",
    "    with pd.ExcelWriter(os.path.join(os.getcwd(), 'Results_CV/' + steel + '_result_CV.xlsx')) as writer:\n",
    "        for df_name, df in scoring.items():\n",
    "            df.to_excel(writer, sheet_name=df_name) \n",
    "    all_results[steel] = results_best_model\n",
    "    with open('Results_CV/all_results_CV.p', 'wb') as fp:\n",
    "        pickle.dump(all_results, fp, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to add another regressor:\n",
    "\n",
    "create a new dictionary in the for loop as for example all_results_ridge dict and comment out other regressors in the model_GSCV dict \n",
    "then the results and rerun pickle save:\n",
    "\n",
    "\n",
    "`for k, v in dict_results.items():\n",
    "    if k in all_results_ridge.keys():\n",
    "        all_results_ridge[k] += v\n",
    "    else:\n",
    "        all_results_ridge[k] = v`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results_CV/Bayes_all_results_CV.p', 'rb') as fp:\n",
    "    dict_results = pickle.load(fp)\n",
    "    print(dict_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metricsel_names = ['Ridge', 'Elastic', 'Tree', 'KNN', 'SVM', 'RF', 'XGB']\n",
    "all_regressors=dict()\n",
    "metrics = pd.DataFrame()\n",
    "\n",
    "for steel in set(X_train_ori.index.str.split('-').str[0]):\n",
    "    \n",
    "    # Create model_dict\n",
    "    list_results = dict_results[steel]\n",
    "    models = dict(zip(model_names, list_results))\n",
    "    \n",
    "    # Fit models\n",
    "    regressors = list()\n",
    "    for name, model in models.items():\n",
    "        reg, pred = train_model(X_train_ori, y_train_ori, X_test_ori, y_test_ori, steel, name, model)\n",
    "        regressors.append(reg)\n",
    "        metrics = metrics.append(pred, ignore_index=True)\n",
    "    all_regressors[steel] = regressors\n",
    "    \n",
    "    \n",
    "    #save params\n",
    "    \n",
    "    with open('Results_CV/all_regressors.p', 'wb') as fp:\n",
    "        pickle.dump(all_regressors, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "metrics.to_csv('Results_reg/RMSE_R2_train_test_simulated_data.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cat = pd.api.types.CategoricalDtype(categories=['Ridge', 'Elastic', 'Tree', 'KNN', 'SVM', 'RF', 'XGB'],\n",
    "                            ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_df = metrics.melt(id_vars=['model', 'type'], \n",
    "                           value_name='RMSE', \n",
    "                           value_vars=['RMSE_train', 'RMSE_test'])\n",
    "RMSE_df.model = RMSE_df.model.astype(model_cat)\n",
    "RMSE_df = RMSE_df[RMSE_df.type != 'A286']\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "g = sns.relplot(x='model', y='RMSE', kind='line', data = RMSE_df, hue = 'variable',\n",
    "           col='type', col_wrap=2,\n",
    "           facet_kws={'sharex': False, 'sharey': False})\n",
    "for yaxes in g.fig.get_axes():\n",
    "    yaxes.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_df = metrics.melt(id_vars=['model', 'type'], \n",
    "                           value_name='R2 score', \n",
    "                           value_vars=['R2_train', 'R2_test'])\n",
    "RMSE_df.model = RMSE_df.model.astype(model_cat)\n",
    "\n",
    "RMSE_df = RMSE_df[RMSE_df.type != 'A286']\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "g = sns.relplot(x='model', y='R2 score', kind='line', data = RMSE_df, hue = 'variable',\n",
    "           col='type', col_wrap=2,\n",
    "           facet_kws={'sharex': False, 'sharey': False})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results_CV/all_regressors.p', 'rb') as fp:\n",
    "    dict_regressors = pickle.load(fp)\n",
    "    print(dict_regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_real, y_val_real = load_data_real(os.path.join(os.path.dirname(os.getcwd()), '../Data/Merged_data/MERGE_FT_TEP_UT_on_ID.csv'),\n",
    "               scaler) # using the scaler from the load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_metrics = pd.DataFrame()\n",
    "\n",
    "for steel in set(X_train_ori.index.str.split('-').str[0]):\n",
    "    \n",
    "    pred = dict()\n",
    "    # Create model_dict\n",
    "    list_reg = dict_regressors[steel]\n",
    "    models = dict(zip(model_names, list_reg))\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        reg_real, score_real= real_pred(steel, X_val_real, y_val_real, model)\n",
    "        \n",
    "        pred['True_FT'] = y_val_real[y_val_real.index.str.contains(steel)]\n",
    "        pred[name] = reg_real\n",
    "        real_metrics = real_metrics.append(score_real, ignore_index=True)\n",
    "    \n",
    "    pd.DataFrame(pred).to_csv('Results_reg/prediction_original_data_' + steel +  '.csv')\n",
    "    #save params\n",
    "real_metrics.to_csv('Results_reg/RMSE_R2_original_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_real_df = all_real_metrics.melt(id_vars=['model', 'type'], \n",
    "                           #value_name=['R2 score', 'RMSE'], \n",
    "                           value_vars=['R2', 'RMSE'])\n",
    "RMSE_real_df.model = RMSE_real_df.model.astype(model_cat)\n",
    "\n",
    "RMSE_real_df = RMSE_real_df[RMSE_real_df.type != 'A286']\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "g = sns.relplot(x='model', y='value', kind='line', data = RMSE_real_df, row = 'variable',\n",
    "           col='type', facet_kws={'sharex': False, 'sharey': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Ridge', 'Elastic', 'Tree', 'KNN', 'SVM', 'RF', 'XGB']\n",
    "sns.set(style='white')\n",
    "for steel in set(X_train_ori.index.str.split('-').str[0]):\n",
    "        \n",
    "    # Create model_dict\n",
    "    list_results = dict_results[steel]\n",
    "    models = dict(zip(model_names, list_results))\n",
    "\n",
    "    for name, model in models.items():\n",
    "        if name == 'KNN' or name == 'SVM':\n",
    "            continue\n",
    "        classic = get_feature_importance(name, model, feature_names)\n",
    "        classic.plot.barh(figsize=(5,5), color=[sns.color_palette(palette='PuBu', n_colors=len(feature_names))], \n",
    "                          legend=False, title=name + ', ' + steel)\n",
    "       \n",
    "        if name=='Ridge' or  name=='Elastic' or name=='SVM':\n",
    "            plt.xlabel('coefficients')\n",
    "\n",
    "        if name=='RF' or name == 'Tree':\n",
    "            plt.xlabel('relative gini importance') \n",
    "            \n",
    "        if name=='XGB':\n",
    "            plt.xlabel('relative weight importance')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS4A-Team18-Vaccine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:EPRI]",
   "language": "python",
   "name": "conda-env-EPRI-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
