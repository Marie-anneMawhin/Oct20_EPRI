{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot coefficient on non-zero coef and gridsearch for alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, glob, inspect, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis, CoxnetSurvivalAnalysis\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()), '../Data/Merged_data/Survival_df.csv'),\n",
    "                  index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y=df.iloc[:, :2]\n",
    "df_x=df.iloc[:, 2:]\n",
    "df_y=df_y.to_records(index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(coefs, n_highlight):\n",
    "    _, ax = plt.subplots(figsize=(12, 8))\n",
    "    n_features = coefs.shape[0]\n",
    "    alphas = coefs.columns\n",
    "    for row in coefs.itertuples():\n",
    "        ax.semilogx(alphas, row[1:], \".-\", label=row.Index)\n",
    "\n",
    "    alpha_min = alphas.min()\n",
    "    top_coefs = coefs.loc[:, alpha_min].map(abs).sort_values().tail(n_highlight)\n",
    "    for name in top_coefs.index:\n",
    "        coef = coefs.loc[name, alpha_min]\n",
    "        plt.text(\n",
    "            alpha_min, coef, name + \"  \",\n",
    "            horizontalalignment=\"right\",\n",
    "            verticalalignment=\"center\"\n",
    "        )\n",
    "\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel(\"alpha\")\n",
    "    ax.set_ylabel(\"coefficient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing penalty strength α by running a GridSearch\n",
    "\n",
    "For prediction, we need to pick one particular α, and the subset of features it implies. Here, we are going to use cross-validation to determine which subset and α generalizes best.\n",
    "\n",
    "Before we can use GridSearchCV, we need to determine the set of α which we want to evaluate. To do this, we fit a penalized Cox model to the whole data and retrieve the estimated set of alphas. Since, we are only interested in alphas and not the coefficients, we can use only a few iterations for improved speed. Note that we are using MinMaxScaler() to account for scale differences among features and allow direct comparison of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coxnet_pipe = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.01, max_iter=10000) \n",
    ")\n",
    "#ConvergenceWarning: Optimization terminated early, you might want to increase the number of iterations (max_iter=100) so increased it to 10000\n",
    "\n",
    "coxnet_pipe.fit(df_x, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10. ** np.linspace(-4, 4, 50) # me make a list of alphas\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "gcv = GridSearchCV(\n",
    "    make_pipeline(MinMaxScaler(), CoxnetSurvivalAnalysis(l1_ratio=0.9)),\n",
    "    param_grid={\"coxnetsurvivalanalysis__alphas\": [[v] for v in alphas]},\n",
    "    cv=cv,\n",
    "    error_score=0.5,\n",
    "    n_jobs=4).fit(df_x, df_y)\n",
    "\n",
    "cv_results = pd.DataFrame(gcv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = cv_results.param_coxnetsurvivalanalysis__alphas.map(lambda x: x[0])\n",
    "mean = cv_results.mean_test_score\n",
    "std = cv_results.std_test_score\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "ax.plot(alphas, mean)\n",
    "ax.fill_between(alphas, mean - std, mean + std, alpha=.15)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_ylabel(\"concordance index\")\n",
    "ax.set_xlabel(\"alpha\")\n",
    "\n",
    "\n",
    "ax.annotate('Concordance Index: 0.6891534391534391 ', xy=(0.05,0.6), xytext=(0.1, 0.65), fontsize=12)\n",
    "ax.axvline(gcv.best_params_[\"coxnetsurvivalanalysis__alphas\"][0], c=\"C1\")\n",
    "ax.axhline(0.5, color=\"grey\", linestyle=\"--\")\n",
    "ax.grid(True)\n",
    "\n",
    "print(\"mean test score:\", cv_results.mean_test_score.max())\n",
    "print(\"alpha for best and generalized fit:\", gcv.best_params_[\"coxnetsurvivalanalysis__alphas\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot the non-zero coefficient at the alpha determined\n",
    "best_model = gcv.best_estimator_.named_steps[\"coxnetsurvivalanalysis\"]\n",
    "best_coefs = pd.DataFrame(\n",
    "    best_model.coef_,\n",
    "    index=df_x.columns,\n",
    "    columns=[\"coefficient\"]\n",
    ")\n",
    "\n",
    "non_zero = np.sum(best_coefs.iloc[:, 0] != 0)\n",
    "print(\"Number of non-zero coefficients: {}\".format(non_zero))\n",
    "\n",
    "non_zero_coefs = best_coefs.query(\"coefficient != 0\")\n",
    "coef_order = non_zero_coefs.abs().sort_values(\"coefficient\").index\n",
    "\n",
    "_, ax = plt.subplots(figsize=(6, 8))\n",
    "non_zero_coefs.loc[coef_order].plot.barh(ax=ax, legend=False)\n",
    "ax.set_xlabel(\"coefficient\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very useful since it only gives 1 feature with a non-zero coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net\n",
    "The LASSO is a great tool to select a subset of discriminative features, but it has two main drawbacks. First, it cannot select more features than number of samples in the training data, which is problematic when dealing with very high-dimensional data. Second, if data contains a group of features that are highly correlated, the LASSO penalty is going to randomly choose one feature from this group. The Elastic Net penalty overcomes these problems by using a weighted combination of the ℓ1 and ℓ2 penalty by solving:\n",
    "\n",
    "            argmaxβlogPL(β)−α(r∑j=1p|βj|+1−r2∑j=1pβ2j),\n",
    "where r∈[0;1[ is the relative weight of the ℓ1 and ℓ2 penalty. The Elastic Net penalty combines the subset selection property of the LASSO with the regularization strength of the Ridge penalty. This leads to better stability compared to the LASSO penalized model. For a group of highly correlated features, the latter would choose one feature randomly, whereas the Elastic Net penalized model would tend to select all. Usually, it is sufficient to give the ℓ2 penalty only a small weight to improve stability of the LASSO, e.g. by setting r=0.9.\n",
    "\n",
    "As for the LASSO, the weight α implicitly determines the size of the selected subset, and usually has to be estimated in a data-driven manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NDE_cycle feature to observe more feature coefficients as it has a significant effect on the elastic net plot\n",
    "df_x.drop(['NDE_cycle'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we plot the elastic net with the same penality parameter of l1_ratio=0.9 to plot coefficient plot\n",
    "\n",
    "cox_elastic_net = CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.01)\n",
    "cox_elastic_net.fit(df_x, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_elastic_net = pd.DataFrame(\n",
    "    cox_elastic_net.coef_,\n",
    "    index=df_x.columns,\n",
    "    columns=np.round(cox_elastic_net.alphas_, 5)\n",
    ")\n",
    "plot_coefficients(coefficients_elastic_net, n_highlight=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot we can see that the alpha value determined above is approx. 0.08 which we can see to have only 1 non-zero from the previous plot but for ther elasticnet plot alpha value below that will give more features to include. The reason for the previous plot above is that corcandence index is not recommend to use when there is a high level of censoring and ipcw index should be used. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
